# -*- coding: utf-8 -*-
"""fault_event_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U9l-VFMwqeRBsn_EfXGj9cImQLVhUfvM
"""

import pandas as pd

df = pd.read_csv('grid_asset_data.csv')
display(df.head())

df.info()
display(df.describe())

"""Fill the missing values in Fault_Event, and Reconfig_Action columns with the appropriate strings."""

fault_event_missing_count = df['Fault_Event'].isnull().sum()
fault_event_missing_percentage = (fault_event_missing_count / len(df)) * 100

reconfig_action_missing_count = df['Reconfig_Action'].isnull().sum()
reconfig_action_missing_percentage = (reconfig_action_missing_count / len(df)) * 100

print(f"Missing values in 'Fault_Event': {fault_event_missing_count} ({fault_event_missing_percentage:.2f}%)")
print(f"Missing values in 'Reconfig_Action': {reconfig_action_missing_count} ({reconfig_action_missing_percentage:.2f}%)")

df['Fault_Event'] = df['Fault_Event'].fillna('No Fault')
df['Reconfig_Action'] = df['Reconfig_Action'].fillna('No Reconfig')

display(df.head())

"""**Reasoning**:
Verify that the missing values have been filled correctly in the specified columns.


"""

print(df['Fault_Event'].isnull().sum())
print(df['Reconfig_Action'].isnull().sum())

df = df.drop(columns=['Timestamp', 'Substation_ID', 'Asset_ID', 'Asset_Type'])
display(df.head())

contingency_table = pd.crosstab(df['Fault_Event'], df['Reconfig_Action'])
print(contingency_table)

df = df.drop(columns=['Reconfig_Action'])
display(df.head())

pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
display(df)

# @title Fault_Event

from matplotlib import pyplot as plt
import seaborn as sns
df.groupby('Fault_Event').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

"""# Task
Train an XGBoost model on the "grid_asset_data.csv" dataset to predict the 'Fault_Event' column. Split the data into 80% training and 20% testing sets. Drop the columns 'Timestamp', 'Substation_ID', 'Asset_ID', 'Asset_Type', and 'Reconfig_Action'. Handle the remaining categorical feature 'Load_Type' using one-hot encoding. Evaluate the model's performance.

## Prepare data for modeling

### Subtask:
Separate the features (X) and the target variable (y).

**Reasoning**:
Separate the features (X) and the target variable (y) based on the instructions.
"""

X = df.drop(columns=['Fault_Event'])
y = df['Fault_Event']
display(X.head())
display(y.head())

"""## Split data

### Subtask:
Split the data into training and testing sets (80% train, 20% test).

**Reasoning**:
Split the data into training and testing sets.
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

"""## Train xgboost model

### Subtask:
Train an XGBoost classifier on the training data.

**Reasoning**:
Import the XGBoost classifier and train the model on the processed training data.
"""

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer

categorical_features = ['Load_Type']

preprocessor = ColumnTransformer(
    transformers=[
        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ],
    remainder='passthrough'
)

X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

print("Shape of X_train_processed:", X_train_processed.shape)
print("Shape of X_test_processed:", X_test_processed.shape)

from sklearn.preprocessing import LabelEncoder
from xgboost import XGBClassifier

le = LabelEncoder()
y_train_encoded = le.fit_transform(y_train)
y_test_encoded = le.transform(y_test)

xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='merror')
xgb_model.fit(X_train_processed, y_train_encoded)

"""## Evaluate model

### Subtask:
Evaluate the trained model's performance on the testing data using appropriate classification metrics (e.g., accuracy, precision, recall, F1-score).

**Reasoning**:
Evaluate the trained model's performance on the testing data using appropriate classification metrics.
"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

y_pred = xgb_model.predict(X_test_processed)

accuracy = accuracy_score(y_test_encoded, y_pred)
precision = precision_score(y_test_encoded, y_pred, average='weighted')
recall = recall_score(y_test_encoded, y_pred, average='weighted')
f1 = f1_score(y_test_encoded, y_pred, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision (weighted): {precision:.4f}")
print(f"Recall (weighted): {recall:.4f}")
print(f"F1-score (weighted): {f1:.4f}")

"""## Summary:

### Data Analysis Key Findings

*   The data was successfully split into 80% training and 20% testing sets.
*   The categorical feature 'Load\_Type' was successfully one-hot encoded, increasing the number of features.
*   The target variable 'Fault\_Event' was label encoded into a numerical format before training the XGBoost model.
*   The trained XGBoost model achieved an accuracy of approximately 86.11\% on the test data.
*   The weighted precision, recall, and F1-score on the test set were approximately 74.71\%, 86.11\%, and 80.01\%, respectively.
*   A warning during evaluation indicated that some classes in the test set had no predicted samples, suggesting potential issues with predicting minority classes.

### Insights or Next Steps

*   Investigate the class distribution of the 'Fault\_Event' column to understand the potential for class imbalance, which might explain the `UndefinedMetricWarning` and lower precision/F1-score compared to accuracy.
*   Consider techniques to address class imbalance, such as oversampling minority classes (e.g., SMOTE) or using evaluation metrics appropriate for imbalanced datasets (e.g., confusion matrix, per-class metrics).

# Task
Evaluate the trained XGBoost model and train and evaluate Logistic Regression, Decision Trees, Random Forests, and Support Vector Machines (SVM) models on the "grid_asset_data.csv" dataset, comparing their performance to predict the 'Fault_Event' column.

## Evaluate xgboost model

### Subtask:
Evaluate the trained XGBoost model's performance on the testing data using appropriate classification metrics.

## Train and evaluate logistic regression

### Subtask:
Train a Logistic Regression model on the preprocessed data and evaluate its performance.

**Reasoning**:
Import LogisticRegression, train the model, make predictions, and evaluate its performance using accuracy, precision, recall, and F1-score.
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

lr_model = LogisticRegression(max_iter=1000)
lr_model.fit(X_train_processed, y_train_encoded)

y_pred_lr = lr_model.predict(X_test_processed)

accuracy_lr = accuracy_score(y_test_encoded, y_pred_lr)
precision_lr = precision_score(y_test_encoded, y_pred_lr, average='weighted')
recall_lr = recall_score(y_test_encoded, y_pred_lr, average='weighted')
f1_lr = f1_score(y_test_encoded, y_pred_lr, average='weighted')

print(f"Logistic Regression Accuracy: {accuracy_lr:.4f}")
print(f"Logistic Regression Precision (weighted): {precision_lr:.4f}")
print(f"Logistic Regression Recall (weighted): {recall_lr:.4f}")
print(f"Logistic Regression F1-score (weighted): {f1_lr:.4f}")

"""## Train and evaluate decision tree

### Subtask:
Train a Decision Tree model on the preprocessed data and evaluate its performance.

**Reasoning**:
Train a Decision Tree model on the preprocessed data and evaluate its performance.
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train_processed, y_train_encoded)

y_pred_dt = dt_model.predict(X_test_processed)

accuracy_dt = accuracy_score(y_test_encoded, y_pred_dt)
precision_dt = precision_score(y_test_encoded, y_pred_dt, average='weighted')
recall_dt = recall_score(y_test_encoded, y_pred_dt, average='weighted')
f1_dt = f1_score(y_test_encoded, y_pred_dt, average='weighted')

print(f"Decision Tree Accuracy: {accuracy_dt:.4f}")
print(f"Decision Tree Precision (weighted): {precision_dt:.4f}")
print(f"Decision Tree Recall (weighted): {recall_dt:.4f}")
print(f"Decision Tree F1-score (weighted): {f1_dt:.4f}")

"""## Train and evaluate random forest

### Subtask:
Train a Random Forest model on the preprocessed data and evaluate its performance.

**Reasoning**:
Train a Random Forest model and evaluate its performance.
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train_processed, y_train_encoded)

y_pred_rf = rf_model.predict(X_test_processed)

accuracy_rf = accuracy_score(y_test_encoded, y_pred_rf)
precision_rf = precision_score(y_test_encoded, y_pred_rf, average='weighted')
recall_rf = recall_score(y_test_encoded, y_pred_rf, average='weighted')
f1_rf = f1_score(y_test_encoded, y_pred_rf, average='weighted')

print(f"Random Forest Accuracy: {accuracy_rf:.4f}")
print(f"Random Forest Precision (weighted): {precision_rf:.4f}")
print(f"Random Forest Recall (weighted): {recall_rf:.4f}")
print(f"Random Forest F1-score (weighted): {f1_rf:.4f}")

"""## Train and evaluate support vector machine (svm)

### Subtask:
Train an SVM model on the preprocessed data and evaluate its performance.

**Reasoning**:
Import the necessary libraries and train the SVM model.
"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

svm_model = SVC(probability=True, random_state=42)
svm_model.fit(X_train_processed, y_train_encoded)

y_pred_svm = svm_model.predict(X_test_processed)

accuracy_svm = accuracy_score(y_test_encoded, y_pred_svm)
precision_svm = precision_score(y_test_encoded, y_pred_svm, average='weighted')
recall_svm = recall_score(y_test_encoded, y_pred_svm, average='weighted')
f1_svm = f1_score(y_test_encoded, y_pred_svm, average='weighted')

print(f"SVM Accuracy: {accuracy_svm:.4f}")
print(f"SVM Precision (weighted): {precision_svm:.4f}")
print(f"SVM Recall (weighted): {recall_svm:.4f}")
print(f"SVM F1-score (weighted): {f1_svm:.4f}")

"""## Compare model performance

### Subtask:
Compare the performance of all trained models based on the evaluation metrics.

**Reasoning**:
I will create a dictionary to store the performance metrics of all the trained models, convert it to a pandas DataFrame, and then display the DataFrame to compare their performance as per the instructions.
"""

performance_data = {
    'Model': ['XGBoost', 'Logistic Regression', 'Decision Tree', 'Random Forest', 'SVM'],
    'Accuracy': [accuracy, accuracy_lr, accuracy_dt, accuracy_rf, accuracy_svm],
    'Precision': [precision, precision_lr, precision_dt, precision_rf, precision_svm],
    'Recall': [recall, recall_lr, recall_dt, recall_rf, recall_svm],
    'F1-score': [f1, f1_lr, f1_dt, f1_rf, f1_svm]
}

performance_df = pd.DataFrame(performance_data)
display(performance_df)

from sklearn.preprocessing import LabelEncoder
from xgboost import XGBClassifier

le = LabelEncoder()
y_train_encoded = le.fit_transform(y_train)
y_test_encoded = le.transform(y_test)

xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='merror')
xgb_model.fit(X_train_processed, y_train_encoded)



import joblib

# Define the filename for the saved model
filename = 'svm_model.joblib'

# Save the model to the file
joblib.dump(svm_model, filename)

print(f"SVM model saved to {filename}")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import joblib

# Load the data
df = pd.read_csv('grid_asset_data.csv')

# Fill missing values
df['Fault_Event'] = df['Fault_Event'].fillna('No Fault')
df['Reconfig_Action'] = df['Reconfig_Action'].fillna('No Reconfig')

# Drop irrelevant columns
df = df.drop(columns=['Timestamp', 'Substation_ID', 'Asset_ID', 'Asset_Type', 'Reconfig_Action'])

# Separate features (X) and target (y)
X = df.drop(columns=['Fault_Event'])
y = df['Fault_Event']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocess categorical features
categorical_features = ['Load_Type']
preprocessor = ColumnTransformer(
    transformers=[
        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ],
    remainder='passthrough'
)

X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

# Encode the target variable
le = LabelEncoder()
y_train_encoded = le.fit_transform(y_train)
y_test_encoded = le.transform(y_test)

# Initialize and train the Random Forest model
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train_processed, y_train_encoded)

# Make predictions and evaluate the model
y_pred_rf = rf_model.predict(X_test_processed)

accuracy_rf = accuracy_score(y_test_encoded, y_pred_rf)
precision_rf = precision_score(y_test_encoded, y_pred_rf, average='weighted', zero_division=0)
recall_rf = recall_score(y_test_encoded, y_pred_rf, average='weighted')
f1_rf = f1_score(y_test_encoded, y_pred_rf, average='weighted')

print(f"Random Forest Accuracy: {accuracy_rf:.4f}")
print(f"Random Forest Precision (weighted): {precision_rf:.4f}")
print(f"Random Forest Recall (weighted): {recall_rf:.4f}")
print(f"Random Forest F1-score (weighted): {f1_rf:.4f}")

"""## Random Forest Model Training and Evaluation

This section demonstrates the complete process of training and evaluating a Random Forest model to predict 'Fault_Event' in the grid asset data.

**Steps:**

1.  **Load the dataset:** Load the data from the "grid_asset_data.csv" file into a pandas DataFrame.
2.  **Handle missing values:** Fill the missing values in the 'Fault_Event' and 'Reconfig_Action' columns.
3.  **Drop irrelevant columns:** Remove columns that are not needed for modeling.
4.  **Separate features and target:** Define the features (X) and the target variable (y).
5.  **Split the data:** Divide the dataset into training and testing sets.
6.  **Preprocess categorical features:** Apply one-hot encoding to the 'Load_Type' column.
7.  **Encode the target variable:** Convert the categorical target variable into numerical labels.
8.  **Train the Random Forest model:** Initialize and train a RandomForestClassifier.
9.  **Evaluate the model:** Make predictions on the test set and evaluate the model's performance using accuracy, precision, recall, and F1-score.
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# 1. Load the data
df = pd.read_csv('grid_asset_data.csv')

# 2. Handle missing values
df['Fault_Event'] = df['Fault_Event'].fillna('No Fault')
df['Reconfig_Action'] = df['Reconfig_Action'].fillna('No Reconfig')

# 3. Drop irrelevant columns
df = df.drop(columns=['Timestamp', 'Substation_ID', 'Asset_ID', 'Asset_Type', 'Reconfig_Action'])

# 4. Separate features (X) and target (y)
X = df.drop(columns=['Fault_Event'])
y = df['Fault_Event']

# 5. Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 6. Preprocess categorical features
categorical_features = ['Load_Type']
preprocessor = ColumnTransformer(
    transformers=[
        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ],
    remainder='passthrough'
)

X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

# 7. Encode the target variable
le = LabelEncoder()
y_train_encoded = le.fit_transform(y_train)
y_test_encoded = le.transform(y_test)

# 8. Train the Random Forest model
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train_processed, y_train_encoded)

# 9. Evaluate the model
y_pred_rf = rf_model.predict(X_test_processed)

accuracy_rf = accuracy_score(y_test_encoded, y_pred_rf)
precision_rf = precision_score(y_test_encoded, y_pred_rf, average='weighted', zero_division=0)
recall_rf = recall_score(y_test_encoded, y_pred_rf, average='weighted')
f1_rf = f1_score(y_test_encoded, y_pred_rf, average='weighted')

print("--- Random Forest Model Performance ---")
print(f"Accuracy: {accuracy_rf:.4f}")
print(f"Precision (weighted): {precision_rf:.4f}")
print(f"Recall (weighted): {recall_rf:.4f}")
print(f"F1-score (weighted): {f1_rf:.4f}")

import joblib

# Define the filename for the saved model
filename = 'fault_event_random_forest_model.joblib'

# Save the model to the file
joblib.dump(rf_model, filename)

print(f"Random Forest model saved to {filename}")